{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21b0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de78cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50  1\n",
       "0  1   85  66  29    0  26.6  0.351  31  0\n",
       "1  8  183  64   0    0  23.3  0.672  32  1\n",
       "2  1   89  66  23   94  28.1  0.167  21  0\n",
       "3  0  137  40  35  168  43.1  2.288  33  1\n",
       "4  5  116  74   0    0  25.6  0.201  30  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv',na_values=['?','??','???','-'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f02e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of row are in dataset =  767 :: the number of columns are =  9\n",
      "The number of missing values are =  0\n",
      "The unique of target values are  = [0 1]\n"
     ]
    }
   ],
   "source": [
    "row_    = df.shape[0]\n",
    "column_ = df.shape[1]\n",
    "\n",
    "print(\"The number of row are in dataset = \",row_,\":: the number of columns are = \",column_)\n",
    "print(\"The number of missing values are = \",df.isnull().sum().sum())\n",
    "print(\"The unique of target values are  =\", df['1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f935db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95fbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_ = StandardScaler()\n",
    "x_train  = scaling_.fit_transform(x_train)\n",
    "x_test   = scaling_.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919866d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression, the accuracy is =  0.7597402597402597\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "predict = lr.predict(x_test)\n",
    "print(\"Using Logistic Regression, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "845e07dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Decision Tree, the accuracy is =  0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "predict = dt.predict(x_test)\n",
    "print(\"Using Decision Tree, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334d375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Extra Tree Classifier, the accuracy is =  0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "et.fit(x_train,y_train)\n",
    "predict = et.predict(x_test)\n",
    "print(\"Using Extra Tree Classifier, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4805eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Random Forest Classifier, the accuracy is =  0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "predict = rf.predict(x_test)\n",
    "print(\"Using Random Forest Classifier, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1384de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Gradient Boosting Classifier, the accuracy is =  0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "gb = RandomForestClassifier()\n",
    "gb.fit(x_train,y_train)\n",
    "predict = gb.predict(x_test)\n",
    "print(\"Using Gradient Boosting Classifier, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13077a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bagging Classifier, the accuracy is =  0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(base_estimator = RandomForestClassifier())\n",
    "bc.fit(x_train,y_train)\n",
    "predict = bc.predict(x_test)\n",
    "print(\"Using Bagging Classifier, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d452741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Using XGB, the accuracy is =  0.7402597402597403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier()\n",
    "xg.fit(x_train,y_train)\n",
    "predict = xg.predict(x_test)\n",
    "print(\"Using XGB, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc77fe5",
   "metadata": {},
   "source": [
    "# Using ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bace6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#creating input layer and first hidden layer\n",
    "model.add(Dense(26, activation = 'relu', kernel_initializer = 'uniform', input_dim = 13))\n",
    "model.add(BatchNormalization())\n",
    "#creating second hidden layer\n",
    "model.add(Dense(13, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "model.add(BatchNormalization())\n",
    "#creating third hidden layer\n",
    "model.add(Dense(7, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "model.add(BatchNormalization())\n",
    "#creating output layer\n",
    "model.add(Dense(1, activation = 'sigmoid', kernel_initializer = 'uniform'))\n",
    "\n",
    "#compile \n",
    "model.compile(optimizer = 'RMSPROP',loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "904889fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 13 but received input with shape (None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4a0fb55420ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 13 but received input with shape (None, 8)\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, batch_size = 100, epochs=140, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)\n",
    "predict = (predict > 0.50)\n",
    "\n",
    "print(\"Using ANN, the accuracy is = \",accuracy_score(predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94966d5",
   "metadata": {},
   "source": [
    "# Using Hyper Parameter Tunning \n",
    "1. Install keras-tuner : pip install -U keras-tuner\n",
    "\n",
    "* How to select appropriate Optimizer\n",
    "* How to select appropriate number of nodes\n",
    "* How to select number of layers(Hidden Layers)\n",
    "* Combine All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2688050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c49f90",
   "metadata": {},
   "source": [
    "# 1. Select the appropriate Optimizer\n",
    "\n",
    "1. Create model\n",
    "\n",
    "*def bulid_model(hp):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, activation = 'relu', kernel_initializers    = 'uniform', input_dim = 13))\n",
    "    model.add(Dense(1,  activation = 'sigmoid', kernel_initializers = 'uniform'))\n",
    "    \n",
    "    compile the model\n",
    "    \n",
    "    optimzer_ = hp.choice('optimizer_lists',values = ['SGD', 'RMSprop', 'Adam', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam'])\n",
    "    model.compile(optimizer = optimzer_, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "                          \n",
    "    return model\n",
    "    \n",
    "2. Create Tunner object\n",
    "\n",
    "*tunner_ = kt.RandomSearch(bulid_model, \n",
    "                          objective  = 'val_accuracy',\n",
    "                          max_trials = 10\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11146955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "def bulid_model(hp):\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    #create input layer and first layer\n",
    "    model.add(Dense(26, activation = 'relu', kernel_initializer    = 'he_uniform', input_dim = 13))\n",
    "    model.add(BatchNormalization())\n",
    "    #create output layer\n",
    "    model.add(Dense(1,  activation = 'sigmoid', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    #compile the model\n",
    "    \n",
    "    optimzer_ = hp.Choice('optimizer_lists',values = ['SGD', 'RMSprop', 'Adam', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam'])\n",
    "    model.compile(optimizer = optimzer_, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "                          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1baf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner_ = kt.RandomSearch(hypermodel   = bulid_model, \n",
    "                          objective    = 'val_accuracy',\n",
    "                          max_trials   = 10,\n",
    "                          directory    ='mydr32335',\n",
    "                          project_name = 'hyper'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner_.search(x_train,y_train,epochs = 30, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081028a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = tunner_.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a162325",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f951d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = tunner_.get_best_models(num_models = 1)[0]\n",
    "model_.fit(x_train,y_train, epochs = 140, validation_data=(x_test,y_test),batch_size=60, initial_epoch=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05881d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_.predict(x_test)\n",
    "predict = predict>0.5\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbd8b4",
   "metadata": {},
   "source": [
    "\n",
    "# Find appropriate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    units = hp.Int('units', min_value = 1, max_value = 100)\n",
    "    model.add(Dense(units = units, activation = 'relu', kernel_initializer = 'he_uniform', input_dim = 13))\n",
    "    model.add(BatchNormalization())\n",
    "    #create output layer\n",
    "    model.add(Dense(1,  activation = 'sigmoid', kernel_initializer = 'he_uniform'))\n",
    "    #compile\n",
    "    model.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(hypermodel = build_model,\n",
    "                         objective = 'val_accuracy',\n",
    "                         max_trials   = 10,\n",
    "                         directory    ='mydr1994283',\n",
    "                         project_name = 'hyper1'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc450b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train,y_train,epochs = 30, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer_ = tuner.get_best_hyperparameters()[0].values\n",
    "best_optimizer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = tuner.get_best_models(num_models = 1)[0]\n",
    "model_.fit(x_train,y_train, epochs = 140, validation_data=(x_test,y_test),batch_size=60, initial_epoch=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b43254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_.predict(x_test)\n",
    "predict = predict>0.5\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1395a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_ = Sequential()\n",
    "model_.add(Dense(units = 53, activation = 'relu', kernel_initializer = 'he_uniform', input_dim = 13))\n",
    "model_.add(BatchNormalization())\n",
    "#create output layer\n",
    "model_.add(Dense(1,  activation = 'sigmoid', kernel_initializer = 'he_uniform'))\n",
    "#compile\n",
    "model_.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#fit\n",
    "model_.fit(x = x_train, y = y_train, batch_size = 60, epochs = 50, initial_epoch = 0, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa471f",
   "metadata": {},
   "source": [
    "# How to find appropriate layers(Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c71d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_(hp):\n",
    "    model = Sequential()\n",
    "    #create input layer \n",
    "    model.add(Dense(53, activation = 'relu', kernel_initializer = hp.Choice('kernel_initializer_', values = ['glorot_normal','glorot_uniform','he_normal','he_uniform','uniform']), input_dim = 13))\n",
    "    model.add(Dropout(hp.Choice('dropout_', values = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "    model.add(BatchNormalization())\n",
    "    for i in range(hp.Int('hidden_layers_', min_value = 1, max_value = 20)):\n",
    "        model.add(Dense(53, activation = hp.Choice('actiation_'+str(i), values = ['relu','tanh','softplus']), kernel_initializer = hp.Choice('kernel_initializer_'+str(i), values = ['glorot_normal','glorot_uniform','he_normal','he_uniform','uniform'])))\n",
    "        model.add(Dropout(hp.Choice('dropout_'+str(i), values = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "        model.add(BatchNormalization())\n",
    "    #create output layer\n",
    "    model.add(Dense(1, activation = 'sigmoid', kernel_initializer = hp.Choice('kernel_initializer_'+str(i), values = ['glorot_normal','glorot_uniform','he_normal','he_uniform','uniform'])))\n",
    "    #compile model\n",
    "    model.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner = kt.RandomSearch(hypermodel = build_model_,\n",
    "                         objective = 'val_accuracy',\n",
    "                         max_trials   = 10,\n",
    "                         directory   = 'mydir994237'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner.search(x_train, y_train, epochs = 30, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_model_ = tunner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7291556",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_model_ = tunner.get_best_models(num_models=1)[0]\n",
    "tune_model_.fit(x_train,y_train,batch_size = 60, epochs= 140, initial_epoch = 6, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39a62c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(hp.Int('num_layers',min_value=1,max_value=20)):\n",
    "        if counter == 0:\n",
    "            model.add(Dense(hp.Int('units' + str(i), min_value=2, max_value=50),activation= hp.Choice('activation' + str(i), values=['relu','tanh','sigmoid']),kernel_initializer = hp.Choice('kernel_initializer_'+str(i), values = ['glorot_normal','glorot_uniform','he_normal','he_uniform','uniform']),input_dim=8))\n",
    "            model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "            model.add(BatchNormalization())\n",
    "        else:\n",
    "            model.add(Dense(hp.Int('units' + str(i), min_value=2, max_value=50),kernel_initializer = hp.Choice('kernel_initializer_'+str(i), values = ['glorot_normal','glorot_uniform','he_normal','he_uniform','uniform']),activation= hp.Choice('activation' + str(i), values=['relu','tanh','sigmoid'])))\n",
    "            model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "            model.add(BatchNormalization())\n",
    "        counter+=1\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid',kernel_initializer = hp.Choice('kernel_initializer_', values = ['glorot_normal','glorot_uniform','he_normal','he_uniform','uniform'])))\n",
    "    model.compile(optimizer=hp.Choice('optimizer',values=['rmsprop','adam','sgd','nadam','adadelta']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb500b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner_ = kt.RandomSearch(hypermodel = build_model,\n",
    "                         objective = 'val_accuracy',\n",
    "                         max_trials   = 50,\n",
    "                         directory   = 'mydir1977718112113617111897',\n",
    "                         project_name = 'jhaa'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89f4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e403f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.701298713684082\n",
      "\n",
      "Best val_accuracy So Far: 0.7662337422370911\n",
      "Total elapsed time: 00h 03m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tunner_.search(x_train, y_train, epochs = 5, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80b3bff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 4,\n",
       " 'units0': 3,\n",
       " 'activation0': 'tanh',\n",
       " 'kernel_initializer_0': 'glorot_uniform',\n",
       " 'dropout0': 0.5,\n",
       " 'kernel_initializer_': 'glorot_uniform',\n",
       " 'optimizer': 'rmsprop',\n",
       " 'units1': 31,\n",
       " 'kernel_initializer_1': 'he_normal',\n",
       " 'activation1': 'tanh',\n",
       " 'dropout1': 0.4,\n",
       " 'units2': 23,\n",
       " 'kernel_initializer_2': 'he_uniform',\n",
       " 'activation2': 'sigmoid',\n",
       " 'dropout2': 0.6,\n",
       " 'units3': 25,\n",
       " 'kernel_initializer_3': 'he_uniform',\n",
       " 'activation3': 'tanh',\n",
       " 'dropout3': 0.1,\n",
       " 'units4': 27,\n",
       " 'kernel_initializer_4': 'he_uniform',\n",
       " 'activation4': 'sigmoid',\n",
       " 'dropout4': 0.5,\n",
       " 'units5': 20,\n",
       " 'kernel_initializer_5': 'glorot_normal',\n",
       " 'activation5': 'tanh',\n",
       " 'dropout5': 0.9,\n",
       " 'units6': 14,\n",
       " 'kernel_initializer_6': 'he_uniform',\n",
       " 'activation6': 'relu',\n",
       " 'dropout6': 0.1,\n",
       " 'units7': 5,\n",
       " 'kernel_initializer_7': 'he_normal',\n",
       " 'activation7': 'relu',\n",
       " 'dropout7': 0.1,\n",
       " 'units8': 4,\n",
       " 'kernel_initializer_8': 'he_normal',\n",
       " 'activation8': 'sigmoid',\n",
       " 'dropout8': 0.8,\n",
       " 'units9': 36,\n",
       " 'kernel_initializer_9': 'he_normal',\n",
       " 'activation9': 'sigmoid',\n",
       " 'dropout9': 0.3,\n",
       " 'units10': 30,\n",
       " 'kernel_initializer_10': 'glorot_uniform',\n",
       " 'activation10': 'sigmoid',\n",
       " 'dropout10': 0.6,\n",
       " 'units11': 25,\n",
       " 'kernel_initializer_11': 'uniform',\n",
       " 'activation11': 'sigmoid',\n",
       " 'dropout11': 0.6,\n",
       " 'units12': 18,\n",
       " 'kernel_initializer_12': 'he_normal',\n",
       " 'activation12': 'sigmoid',\n",
       " 'dropout12': 0.7,\n",
       " 'units13': 12,\n",
       " 'kernel_initializer_13': 'uniform',\n",
       " 'activation13': 'relu',\n",
       " 'dropout13': 0.9,\n",
       " 'units14': 45,\n",
       " 'kernel_initializer_14': 'uniform',\n",
       " 'activation14': 'relu',\n",
       " 'dropout14': 0.1,\n",
       " 'units15': 2,\n",
       " 'kernel_initializer_15': 'uniform',\n",
       " 'activation15': 'sigmoid',\n",
       " 'dropout15': 0.2,\n",
       " 'units16': 13,\n",
       " 'kernel_initializer_16': 'uniform',\n",
       " 'activation16': 'relu',\n",
       " 'dropout16': 0.4,\n",
       " 'units17': 31,\n",
       " 'kernel_initializer_17': 'glorot_normal',\n",
       " 'activation17': 'relu',\n",
       " 'dropout17': 0.8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunner_.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7b44fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tunner_.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4caed406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5435 - accuracy: 0.7259 - val_loss: 0.5633 - val_accuracy: 0.7143\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5335 - accuracy: 0.7113 - val_loss: 0.5661 - val_accuracy: 0.7143\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5521 - accuracy: 0.7210 - val_loss: 0.5659 - val_accuracy: 0.7143\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5440 - accuracy: 0.7325 - val_loss: 0.5665 - val_accuracy: 0.7143\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7064 - val_loss: 0.5606 - val_accuracy: 0.7143\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5423 - accuracy: 0.7015 - val_loss: 0.5610 - val_accuracy: 0.7208\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.7080 - val_loss: 0.5688 - val_accuracy: 0.7013\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7194 - val_loss: 0.5656 - val_accuracy: 0.7078\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7325 - val_loss: 0.5695 - val_accuracy: 0.7078\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7243 - val_loss: 0.5714 - val_accuracy: 0.7078\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7292 - val_loss: 0.5721 - val_accuracy: 0.7013\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5353 - accuracy: 0.7390 - val_loss: 0.5713 - val_accuracy: 0.7143\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5616 - accuracy: 0.7080 - val_loss: 0.5633 - val_accuracy: 0.7143\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5394 - accuracy: 0.7243 - val_loss: 0.5599 - val_accuracy: 0.7208\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5359 - accuracy: 0.7031 - val_loss: 0.5624 - val_accuracy: 0.7273\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7488 - val_loss: 0.5643 - val_accuracy: 0.7143\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5541 - accuracy: 0.7031 - val_loss: 0.5590 - val_accuracy: 0.7143\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.6884 - val_loss: 0.5551 - val_accuracy: 0.7078\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.7308 - val_loss: 0.5637 - val_accuracy: 0.7078\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7194 - val_loss: 0.5664 - val_accuracy: 0.6948\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5372 - accuracy: 0.7243 - val_loss: 0.5656 - val_accuracy: 0.7078\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.7259 - val_loss: 0.5668 - val_accuracy: 0.7078\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7325 - val_loss: 0.5608 - val_accuracy: 0.7143\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5501 - accuracy: 0.7259 - val_loss: 0.5616 - val_accuracy: 0.7143\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5343 - accuracy: 0.7390 - val_loss: 0.5634 - val_accuracy: 0.7143\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.7471 - val_loss: 0.5662 - val_accuracy: 0.7143\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.7080 - val_loss: 0.5601 - val_accuracy: 0.7143\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5545 - accuracy: 0.7096 - val_loss: 0.5616 - val_accuracy: 0.7078\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5590 - accuracy: 0.7178 - val_loss: 0.5626 - val_accuracy: 0.7078\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5398 - accuracy: 0.7292 - val_loss: 0.5639 - val_accuracy: 0.7078\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5394 - accuracy: 0.7292 - val_loss: 0.5642 - val_accuracy: 0.7078\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5504 - accuracy: 0.73 - 0s 9ms/step - loss: 0.5396 - accuracy: 0.7341 - val_loss: 0.5633 - val_accuracy: 0.7143\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.7259 - val_loss: 0.5700 - val_accuracy: 0.7013\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.7113 - val_loss: 0.5686 - val_accuracy: 0.7078\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5137 - accuracy: 0.7520 - val_loss: 0.5727 - val_accuracy: 0.7013\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7423 - val_loss: 0.5786 - val_accuracy: 0.7013\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7162 - val_loss: 0.5748 - val_accuracy: 0.7013\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5302 - accuracy: 0.7390 - val_loss: 0.5755 - val_accuracy: 0.7078\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5481 - accuracy: 0.7227 - val_loss: 0.5678 - val_accuracy: 0.7078\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7423 - val_loss: 0.5707 - val_accuracy: 0.7078\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5371 - accuracy: 0.7243 - val_loss: 0.5719 - val_accuracy: 0.7078\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5258 - accuracy: 0.7325 - val_loss: 0.5712 - val_accuracy: 0.7078\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.7455 - val_loss: 0.5732 - val_accuracy: 0.7078\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7129 - val_loss: 0.5655 - val_accuracy: 0.7078\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7374 - val_loss: 0.5672 - val_accuracy: 0.7078\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5247 - accuracy: 0.7455 - val_loss: 0.5732 - val_accuracy: 0.7013\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.7210 - val_loss: 0.5715 - val_accuracy: 0.7013\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7292 - val_loss: 0.5680 - val_accuracy: 0.7013\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7276 - val_loss: 0.5708 - val_accuracy: 0.7013\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7276 - val_loss: 0.5762 - val_accuracy: 0.7013\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7341 - val_loss: 0.5710 - val_accuracy: 0.7013\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7325 - val_loss: 0.5715 - val_accuracy: 0.7078\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.7227 - val_loss: 0.5724 - val_accuracy: 0.7013\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5290 - accuracy: 0.7341 - val_loss: 0.5748 - val_accuracy: 0.7013\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.7423 - val_loss: 0.5704 - val_accuracy: 0.7078\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5416 - accuracy: 0.7129 - val_loss: 0.5653 - val_accuracy: 0.7078\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7276 - val_loss: 0.5691 - val_accuracy: 0.7078\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5454 - accuracy: 0.7145 - val_loss: 0.5671 - val_accuracy: 0.7078\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.7390 - val_loss: 0.5699 - val_accuracy: 0.7078\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7227 - val_loss: 0.5690 - val_accuracy: 0.7078\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7325 - val_loss: 0.5733 - val_accuracy: 0.7078\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7243 - val_loss: 0.5643 - val_accuracy: 0.7078\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7243 - val_loss: 0.5605 - val_accuracy: 0.7078\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7243 - val_loss: 0.5608 - val_accuracy: 0.7078\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7406 - val_loss: 0.5595 - val_accuracy: 0.7078\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.7341 - val_loss: 0.5627 - val_accuracy: 0.7078\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7276 - val_loss: 0.5577 - val_accuracy: 0.7078\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7586 - val_loss: 0.5619 - val_accuracy: 0.7078\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5513 - accuracy: 0.7341 - val_loss: 0.5590 - val_accuracy: 0.7078\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.7455 - val_loss: 0.5645 - val_accuracy: 0.7078\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7406 - val_loss: 0.5691 - val_accuracy: 0.7078\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5258 - accuracy: 0.7259 - val_loss: 0.5675 - val_accuracy: 0.7078\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5408 - accuracy: 0.7243 - val_loss: 0.5672 - val_accuracy: 0.7078\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7374 - val_loss: 0.5663 - val_accuracy: 0.7078\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7390 - val_loss: 0.5723 - val_accuracy: 0.7078\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5234 - accuracy: 0.7455 - val_loss: 0.5738 - val_accuracy: 0.7078\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5383 - accuracy: 0.7292 - val_loss: 0.5702 - val_accuracy: 0.7078\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7455 - val_loss: 0.5708 - val_accuracy: 0.7078\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7194 - val_loss: 0.5659 - val_accuracy: 0.7078\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7390 - val_loss: 0.5646 - val_accuracy: 0.7078\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.7325 - val_loss: 0.5605 - val_accuracy: 0.7013\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7439 - val_loss: 0.5577 - val_accuracy: 0.7078\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7292 - val_loss: 0.5605 - val_accuracy: 0.7013\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.7259 - val_loss: 0.5592 - val_accuracy: 0.7013\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7178 - val_loss: 0.5550 - val_accuracy: 0.7013\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7390 - val_loss: 0.5625 - val_accuracy: 0.7013\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.7471 - val_loss: 0.5659 - val_accuracy: 0.7013\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.7455 - val_loss: 0.5638 - val_accuracy: 0.7013\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7341 - val_loss: 0.5658 - val_accuracy: 0.7013\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5345 - accuracy: 0.7227 - val_loss: 0.5631 - val_accuracy: 0.7013\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7553 - val_loss: 0.5667 - val_accuracy: 0.7143\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5120 - accuracy: 0.7635 - val_loss: 0.5724 - val_accuracy: 0.7078\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7292 - val_loss: 0.5660 - val_accuracy: 0.7078\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7537 - val_loss: 0.5665 - val_accuracy: 0.7078\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5387 - accuracy: 0.7455 - val_loss: 0.5619 - val_accuracy: 0.7078\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5343 - accuracy: 0.7308 - val_loss: 0.5609 - val_accuracy: 0.7078\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7080 - val_loss: 0.5543 - val_accuracy: 0.7078\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5479 - accuracy: 0.7210 - val_loss: 0.5544 - val_accuracy: 0.7078\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.7325 - val_loss: 0.5571 - val_accuracy: 0.7078\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.7308 - val_loss: 0.5622 - val_accuracy: 0.7013\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.7341 - val_loss: 0.5619 - val_accuracy: 0.7078\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5343 - accuracy: 0.7390 - val_loss: 0.5624 - val_accuracy: 0.7078\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5407 - accuracy: 0.7292 - val_loss: 0.5618 - val_accuracy: 0.7078\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5326 - accuracy: 0.7292 - val_loss: 0.5580 - val_accuracy: 0.7078\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5287 - accuracy: 0.7259 - val_loss: 0.5580 - val_accuracy: 0.7078\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5228 - accuracy: 0.7210 - val_loss: 0.5600 - val_accuracy: 0.7013\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.7243 - val_loss: 0.5584 - val_accuracy: 0.7078\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5177 - accuracy: 0.7423 - val_loss: 0.5620 - val_accuracy: 0.7078\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5112 - accuracy: 0.7439 - val_loss: 0.5605 - val_accuracy: 0.7078\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5218 - accuracy: 0.7423 - val_loss: 0.5614 - val_accuracy: 0.7078\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5555 - accuracy: 0.7031 - val_loss: 0.5558 - val_accuracy: 0.7078\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5240 - accuracy: 0.7276 - val_loss: 0.5570 - val_accuracy: 0.7078\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5287 - accuracy: 0.7227 - val_loss: 0.5536 - val_accuracy: 0.7078\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5483 - accuracy: 0.7031 - val_loss: 0.5505 - val_accuracy: 0.7078\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.7569 - val_loss: 0.5520 - val_accuracy: 0.7078\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5230 - accuracy: 0.7439 - val_loss: 0.5560 - val_accuracy: 0.7013\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5407 - accuracy: 0.7210 - val_loss: 0.5542 - val_accuracy: 0.7078\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7357 - val_loss: 0.5571 - val_accuracy: 0.7013\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5448 - accuracy: 0.7227 - val_loss: 0.5550 - val_accuracy: 0.7078\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5296 - accuracy: 0.7292 - val_loss: 0.5561 - val_accuracy: 0.7013\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5216 - accuracy: 0.7357 - val_loss: 0.5603 - val_accuracy: 0.7078\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5189 - accuracy: 0.7390 - val_loss: 0.5660 - val_accuracy: 0.7013\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.7406 - val_loss: 0.5686 - val_accuracy: 0.7013\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5343 - accuracy: 0.7243 - val_loss: 0.5647 - val_accuracy: 0.7013\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5405 - accuracy: 0.7210 - val_loss: 0.5613 - val_accuracy: 0.7013\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5078 - accuracy: 0.7471 - val_loss: 0.5659 - val_accuracy: 0.7013\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.7537 - val_loss: 0.5637 - val_accuracy: 0.7013\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5283 - accuracy: 0.7227 - val_loss: 0.5625 - val_accuracy: 0.7013\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7357 - val_loss: 0.5612 - val_accuracy: 0.7013\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.7259 - val_loss: 0.5650 - val_accuracy: 0.7013\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5252 - accuracy: 0.7488 - val_loss: 0.5595 - val_accuracy: 0.7143\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5055 - accuracy: 0.7520 - val_loss: 0.5641 - val_accuracy: 0.7078\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5356 - accuracy: 0.7243 - val_loss: 0.5618 - val_accuracy: 0.7013\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7178 - val_loss: 0.5560 - val_accuracy: 0.7013\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5046 - accuracy: 0.7374 - val_loss: 0.5606 - val_accuracy: 0.7013\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5399 - accuracy: 0.7374 - val_loss: 0.5577 - val_accuracy: 0.7143\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5429 - accuracy: 0.7178 - val_loss: 0.5548 - val_accuracy: 0.7078\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.7357 - val_loss: 0.5533 - val_accuracy: 0.7143\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7553 - val_loss: 0.5535 - val_accuracy: 0.7208\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5350 - accuracy: 0.7243 - val_loss: 0.5537 - val_accuracy: 0.7143\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5375 - accuracy: 0.7455 - val_loss: 0.5502 - val_accuracy: 0.7078\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.7439 - val_loss: 0.5549 - val_accuracy: 0.7078\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.7308 - val_loss: 0.5578 - val_accuracy: 0.7013\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5409 - accuracy: 0.7325 - val_loss: 0.5538 - val_accuracy: 0.7078\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5384 - accuracy: 0.7145 - val_loss: 0.5529 - val_accuracy: 0.7078\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5152 - accuracy: 0.7520 - val_loss: 0.5591 - val_accuracy: 0.7013\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7308 - val_loss: 0.5520 - val_accuracy: 0.7013\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.7227 - val_loss: 0.5493 - val_accuracy: 0.7078\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.7243 - val_loss: 0.5525 - val_accuracy: 0.7078\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.7325 - val_loss: 0.5581 - val_accuracy: 0.7078\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.7259 - val_loss: 0.5631 - val_accuracy: 0.7013\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.7553 - val_loss: 0.5589 - val_accuracy: 0.7078\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5264 - accuracy: 0.7455 - val_loss: 0.5556 - val_accuracy: 0.7143\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7357 - val_loss: 0.5574 - val_accuracy: 0.7143\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7439 - val_loss: 0.5575 - val_accuracy: 0.7143\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5245 - accuracy: 0.7276 - val_loss: 0.5561 - val_accuracy: 0.7208\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5350 - accuracy: 0.7243 - val_loss: 0.5522 - val_accuracy: 0.7143\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5198 - accuracy: 0.7357 - val_loss: 0.5534 - val_accuracy: 0.7273\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.7439 - val_loss: 0.5505 - val_accuracy: 0.7338\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5116 - accuracy: 0.7586 - val_loss: 0.5514 - val_accuracy: 0.7338\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.7390 - val_loss: 0.5556 - val_accuracy: 0.7208\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5253 - accuracy: 0.7471 - val_loss: 0.5521 - val_accuracy: 0.7208\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7276 - val_loss: 0.5533 - val_accuracy: 0.7208\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5425 - accuracy: 0.7194 - val_loss: 0.5533 - val_accuracy: 0.7208\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5203 - accuracy: 0.7471 - val_loss: 0.5531 - val_accuracy: 0.7338\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5280 - accuracy: 0.7390 - val_loss: 0.5550 - val_accuracy: 0.7273\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5179 - accuracy: 0.7292 - val_loss: 0.5539 - val_accuracy: 0.7273\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7537 - val_loss: 0.5543 - val_accuracy: 0.7338\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5243 - accuracy: 0.7439 - val_loss: 0.5558 - val_accuracy: 0.7273\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7537 - val_loss: 0.5537 - val_accuracy: 0.7273\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7553 - val_loss: 0.5518 - val_accuracy: 0.7273\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7292 - val_loss: 0.5517 - val_accuracy: 0.7273\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7357 - val_loss: 0.5496 - val_accuracy: 0.7273\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5228 - accuracy: 0.7390 - val_loss: 0.5490 - val_accuracy: 0.7338\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7194 - val_loss: 0.5476 - val_accuracy: 0.7273\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7406 - val_loss: 0.5525 - val_accuracy: 0.7208\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.7357 - val_loss: 0.5516 - val_accuracy: 0.7273\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.7374 - val_loss: 0.5528 - val_accuracy: 0.7143\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.7227 - val_loss: 0.5516 - val_accuracy: 0.7208\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5311 - accuracy: 0.7243 - val_loss: 0.5511 - val_accuracy: 0.7208\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7292 - val_loss: 0.5480 - val_accuracy: 0.7208\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5459 - accuracy: 0.7080 - val_loss: 0.5447 - val_accuracy: 0.7208\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7113 - val_loss: 0.5450 - val_accuracy: 0.7143\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7047 - val_loss: 0.5452 - val_accuracy: 0.7078\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7308 - val_loss: 0.5451 - val_accuracy: 0.7143\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5463 - accuracy: 0.7210 - val_loss: 0.5436 - val_accuracy: 0.7143\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.7423 - val_loss: 0.5440 - val_accuracy: 0.7208\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7325 - val_loss: 0.5477 - val_accuracy: 0.7208\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7357 - val_loss: 0.5457 - val_accuracy: 0.7273\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5317 - accuracy: 0.7325 - val_loss: 0.5464 - val_accuracy: 0.7338\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5299 - accuracy: 0.7357 - val_loss: 0.5470 - val_accuracy: 0.7273\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5197 - accuracy: 0.7374 - val_loss: 0.5488 - val_accuracy: 0.7273\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5381 - accuracy: 0.7145 - val_loss: 0.5490 - val_accuracy: 0.7208\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7259 - val_loss: 0.5499 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219bc51c100>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=200,batch_size = 60, initial_epoch=6,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3287eb46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d99a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
